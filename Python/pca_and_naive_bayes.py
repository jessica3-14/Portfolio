# -*- coding: utf-8 -*-
"""PCA_and_Naive_Bayes.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1jWZVcVbw4dVOcOOVYVSHRI4judoXXvnN
"""

import numpy as np
import matplotlib.pyplot as plt

# fix seed for consistent results
np.random.seed(1234)

"""
Data set 1 : D1 = spiral like data

- This is a variation on the parametric plot for a circle [cos(t), sin(t)], with a gradually increasing radius. 
"""

# data set 1 [x, y]
t = np.random.rand(400)*np.pi*4
x = np.array([(t+1)*np.sin(t+5), (t+1)*np.cos(t+5)])
y = np.array([-(t+1)*np.sin(t+5) ,-(t+1)*np.cos(t+5)])

# .T means transpose
# - each row in D1 is now an input sample. 
D1 = np.vstack((x.T,y.T))

# Plot it
# -- add your plotting code here
fig=plt.figure()
ax=fig.add_subplot(1,1,1)
ax.set_aspect(1)
plt.plot(D1[:,0],D1[:,1],".")

"""
Data set 2 : D2 = point cloud data (normal distribution)
"""

x = np.append(np.random.normal(0,1,400),   np.random.normal(5.3,2,400))
y = np.append(np.random.normal(0,1,400),   np.random.normal(5.3,2,400))

D2 = np.vstack((x,y)).T

# Plot it 
# -- add your plotting code here
fig=plt.figure()
ax=fig.add_subplot(1,1,1)
ax.set_aspect(1)
plt.plot(D2[:,0],D2[:,1],".")

"""
Data set 3: D3 = simple data
"""

D3 = np.array([[-1, -1], [-2, -1], [-2,-1.75], [-3, -2], [1, 1], [2, 1], [2, 1.75], [3, 2]])

# Plot it
# -- add your plotting code here
fig=plt.figure()
ax=fig.add_subplot(1,1,1)
ax.set_aspect(1)
plt.plot(D3[:,0],D3[:,1],".")

"""
Write your PCA code here
"""

from sklearn.decomposition import PCA
X = D1

# plot data
fig1=plt.figure()
ax=fig1.add_subplot(1,1,1)
ax.set_aspect(1)

plt.plot(X[:,0],X[:,1],"*")

# run PCA analysis: Note: singularvalues are the eigenvalues.
pca = PCA(n_components=2)
pca.fit(X)
print("D1")
print("Singular values (eigenvalues)=")
print(pca.singular_values_)

# plot projection
Z=pca.fit_transform(X)

fig2=plt.figure()
ax2=fig2.add_subplot(1,1,1)
ax2.set_aspect(1)
plt.plot(Z[:,0],Z[:,1],"x")

# data: this is the same as D3 from above 
X = D2


# plot data
fig1=plt.figure()
ax=fig1.add_subplot(1,1,1)
ax.set_aspect(1)

plt.plot(X[:,0],X[:,1],"*")

# run PCA analysis: Note: singularvalues are the eigenvalues.
pca = PCA(n_components=2)
pca.fit(X)
print("D2")
print("Singular values (eigenvalues)=")
print(pca.singular_values_)

# plot projection
Z=pca.fit_transform(X)

fig2=plt.figure()
ax2=fig2.add_subplot(1,1,1)
ax2.set_aspect(1)
plt.plot(Z[:,0],Z[:,1],"x")


X = np.array([[-1, -1], [-2, -1], [-2,-1.75], [-3, -2], [1, 1], [2, 1], [2, 1.75], [3, 2]])


# plot data
fig1=plt.figure()
ax=fig1.add_subplot(1,1,1)
ax.set_aspect(1)

plt.plot(X[:,0],X[:,1],"*")

# run PCA analysis: Note: singularvalues are the eigenvalues.
pca = PCA(n_components=2)
pca.fit(X)
print("D3")
print("Singular values (eigenvalues)=")
print(pca.singular_values_)

# plot projection
Z=pca.fit_transform(X)

fig2=plt.figure()
ax2=fig2.add_subplot(1,1,1)
ax2.set_aspect(1)
plt.plot(Z[:,0],Z[:,1],"x")

import numpy as np
from sklearn.naive_bayes import MultinomialNB

#-------
# dictionary, to look up words from the data vector -- case sensitive! 
#-------
dictionary = np.array(["congrats","you","are","selected","won","lottery","travel","for","free","credit","cards","very","good","night"])

#-------
# vec2word: convert data vector to words
#-------
def vec2word(vec):
  """
  arguments: vec = np.array([0,1,...])
  returns: string of sentence corresponsing to the vector (word may not be ordered properly)
  """
  st=""
  for i in range(14):
    if(vec[i]==1):
      st+=dictionary[i]+" "

  # return ...
  return st

#-------
# word3vec: convert sentence to data vector
#-------
def word2vec(sentence):
  """
  arguments: sentence = "hello you are selected".
  returns: string of sentence corresponsing to the vector (word may not be ordered properly)
  """

  # hint: use "split()" 
  vec=np.zeros(14)
  words = sentence.split()
  for a in words:
    for i in range(14):
      if a==dictionary[i]:
          vec[i]=1
      

  # return ...
  return vec

#--------------------------------
# spam data : enter your data here 
#--------------------------------
# sentence vectors
X = np.array([
 [1,1,1,1,0,0,0,0,0,0,0,0,0,0],
 [0,0,0,0,0,0,1,1,1,0,0,0,0,0],
 [1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,]
,[0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0,]
,[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0,]
,[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,]
,[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,]
])


# target values (spam=1, not spam=0)
y = np.array([0,
              1,1,1,0,0,1])

# 0. use vec2word to test the data accuracy 
print(vec2word(X[0]))
print(vec2word(X[1]))


# 1. Set up model and train 
clf = MultinomialNB()
clf.fit(X, y)

# 2. Training result
print("Training Score (accuracy: 1.0 = 100%)= ",end="")
print(clf.score(X,y),"\n")

# 3. Test sentence
print("Spam test: you won lottery")
test = np.array([[0,1,0,0,1,1,0,0,0,0,0,0,0,0]]) # note: np.array([[ ... ]]), not np.array([ ... ]) 

# 4. test your word2vec() function here, with the test data. 
print("  answer                     = ", clf.predict(test))
print("  nospam vs spam probability = ", clf.predict_proba(test))  # [1. 0.] correspond to NoSpam and Spam probability, respectively.

print("Spam test: free lottery won travel you")
test = np.array([word2vec("free lottery won travel you")]) # note: np.array([[ ... ]]), not np.array([ ... ]) 


print("  answer                     = ", clf.predict(test))
print("  nospam vs spam probability = ", clf.predict_proba(test))

print("Spam test: good very night you")
test = np.array([word2vec("good very night you")]) # note: np.array([[ ... ]]), not np.array([ ... ]) 


print("  answer                     = ", clf.predict(test))
print("  nospam vs spam probability = ", clf.predict_proba(test))

print("Spam test: for credit cards very good")
test = np.array([word2vec("for credit cards very good")]) # note: np.array([[ ... ]]), not np.array([ ... ]) 


print("  answer                     = ", clf.predict(test))
print("  nospam vs spam probability = ", clf.predict_proba(test))

print("Spam test: selected travel congrats for you")
test = np.array([word2vec("selected travel congrats for you")]) # note: np.array([[ ... ]]), not np.array([ ... ]) 


print("  answer                     = ", clf.predict(test))
print("  nospam vs spam probability = ", clf.predict_proba(test))

print("Spam test: night good selected for you")
test = np.array([word2vec("night good selected for you")]) # note: np.array([[ ... ]]), not np.array([ ... ]) 


print("  answer                     = ", clf.predict(test))
print("  nospam vs spam probability = ", clf.predict_proba(test))

print("Spam test: congrats are you very good selected")
test = np.array([word2vec("congrats are you very good selected")]) # note: np.array([[ ... ]]), not np.array([ ... ]) 


print("  answer                     = ", clf.predict(test))
print("  nospam vs spam probability = ", clf.predict_proba(test))